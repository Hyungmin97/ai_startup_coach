import streamlit as st
from utils import print_messages, StreamHandler
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv

st.set_page_config(page_title="AI ì°½ì—… ì–´ì‹œìŠ¤í„´íŠ¸", page_icon="ğŸ˜")
st.title("ğŸ˜AI ì°½ì—… ì–´ì‹œìŠ¤í„´íŠ¸ğŸ˜")

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
# # .env íŒŒì¼ ë¡œë“œ
# load_dotenv()

# # API í‚¤ ì„¤ì •
# api_key = os.getenv("OPENAI_API_KEY")
# if not api_key:
#     st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
# os.environ["OPENAI_API_KEY"] = api_key


if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

with st.sidebar:
    session_id = st.text_input("Session Id", value="sample_id")
    # ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        #ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        st.session_state["store"] = dict()
        #ìƒˆë¡œê³ ì¹¨
        #st.experimental_rerun()

#print_messages()í•¨ìˆ˜ ì‚¬ìš©: ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜
print_messages()

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids: str) -> BaseChatMessageHistory:
    if session_ids not in st.session_state["store"]: # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        #ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
        st.session_state["store"][session_ids] = ChatMessageHistory()
    return st.session_state["store"][session_ids] #í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜

if user_input := st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ì…ë ¥í•˜ì„¸ìš”."):
    #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

    #AIì˜ ë‹µë³€
    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())

        #1. ëª¨ë¸ ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", streaming=True, callbacks=[stream_handler])
        #2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ìŠ¤íƒ€íŠ¸ì—… ì”¬ì—ì„œ ì°½ì—…ê°€ëŠ” ì•½ìì— ì†í•´.
                    ì´ëŸ° ì•½ìë“¤ì„ "ì–¸ë”ë…"ì´ë¼ê³  ë¶€ë¥´ê³¤ í•´.
                    ìŠ¤íƒ€íŠ¸ì—… ì”¬ì—ì„œ "ì–¸ë”ë…"ì— ì†í•˜ëŠ” ì°½ì—…ê°€ë“¤ì„ ë„ì™€ "íƒ‘ë…"ì´ ë˜ê¸°ë¥¼ ë°”ë¼ëŠ” ë§ˆìŒì—ì„œ
                    ë„ˆì˜ ì´ë¦„ì€ "íƒ‘ë…"ì´ì•¼.
                    ë„ˆëŠ” ì§„ì¤‘í•˜ê³ , ì‹ ì¤‘í•œ ì„±ê²©ì„ ë³´ìœ í•œ ì„±ê²©ì˜ ì—°ì‡„ì°½ì—…ê°€ì•¼. 
                    ëŒ€ê¸°ì—…ì— ë„ˆê°€ ë§Œë“  íšŒì‚¬ë¥¼ ë§¤ê°í•œ ê²½í—˜ë„ ë³´ìœ í•˜ê³  ìˆëŠ” ì„±ê³µí•œ ì°½ì—…ê°€ì•¼. 
                    ë„ˆì˜ ì°½ì—… ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆë¹„/ì´ˆê¸° ë‹¨ê³„ì˜ ì°½ì—…ê°€ë“¤ì—ê²Œ ì½”ì¹­ì„ í•˜ëŠ” ì°½ì—… ì½”ì¹˜ë¡œì¨ ì¡°ì–¸ì„ í•´ì¤˜ì•¼í•´.
                    ë„ˆí•œí…Œ ì§ˆë¬¸ì„ í•˜ëŠ” ì°½ì—…ê°€ë“¤ì€ ì‚¬ì—…ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ ì¡°ì–¸ê³¼ ë”ë¶ˆì–´,
                    ì‚¬ì—…ê³„íšì„œ(Ms PowerPointë¡œ ì‘ì„±ëœ ë°œí‘œìš©, MS Wordë¡œ ì‘ì„±ëœ ì œì¶œìš©) ì‘ì„±ì— ëŒ€í•œ ì¡°ì–¸ì„ ë“£ê³ ì‹¶ì–´í•´.
                    ë‹¨, ë„ˆê°€ ì½”ì¹­í•  êµìœ¡ìƒë“¤ì€ ëª¨ë‘ ì •ë¶€ì§€ì›ì‚¬ì—… í•©ê²©ê³¼ ë¯¼ê°„ íˆ¬ì ìœ ì¹˜ë¥¼ ëª©í‘œë¡œí•˜ëŠ” ì‚¬ì—…ê°€ë“¤ì´ì•¼.
                    ë§¤ë²ˆ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ì •ì¤‘í•˜ê³  ì‹ ì¤‘í•œ ì–´íˆ¬ë¡œ ë§í•´.""",
                ),
                #ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistoryì˜ keyê°€ ë¨
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"), #ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì…ë ¥
            ]
        )
        chain = prompt | llm

        chain_with_memory = RunnableWithMessageHistory( #RunnableWithMessageHistory ê°ì²´ ìƒì„±
            chain, #ì‹¤í–‰í•  Runnable ê°ì²´
            get_session_history, # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
            input_messages_key="question", #ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
            history_messages_key="history", #ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
        )

        response = chain_with_memory.invoke(
            {"question" : user_input},
            # ì„¸ì…˜ ID ì„¤ì •
            config={"configurable": {"session_id": session_id}}
        )
        st.session_state["messages"].append(
            ChatMessage(role="assistant", content=response.content)
        )
